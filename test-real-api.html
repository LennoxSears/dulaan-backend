<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real API Test Runner</title>
    <style>
        body {
            font-family: 'Courier New', monospace;
            background: #1a1a1a;
            color: #00ff00;
            padding: 20px;
            line-height: 1.4;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .test-output {
            background: #000;
            border: 1px solid #333;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
            white-space: pre-wrap;
            font-size: 14px;
            max-height: 600px;
            overflow-y: auto;
        }
        .button {
            background: #333;
            color: #00ff00;
            border: 1px solid #555;
            padding: 10px 20px;
            cursor: pointer;
            margin: 10px 5px;
            border-radius: 3px;
        }
        .button:hover {
            background: #555;
        }
        .button:disabled {
            background: #222;
            color: #666;
            cursor: not-allowed;
        }
        .success { color: #00ff00; }
        .error { color: #ff4444; }
        .warning { color: #ffaa00; }
        .info { color: #4488ff; }
        h1, h2 { color: #ffffff; }
        .stats {
            background: #222;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
        }
        .api-info {
            background: #1a3a1a;
            padding: 10px;
            border-radius: 3px;
            margin: 10px 0;
            border-left: 3px solid #00ff00;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🚀 Real API Test Runner</h1>
        <p>Testing actual Firebase speechToTextWithLLM function with multi-language audio samples</p>
        
        <div class="api-info">
            <strong>🔗 API Endpoint:</strong> https://speechtotextwithllm-qveg3gkwxa-ew.a.run.app<br>
            <strong>🎯 Test Type:</strong> Real Google Speech-to-Text + Gemini LLM<br>
            <strong>📊 Audio Format:</strong> Int16Array (LINEAR16 PCM, 16kHz) - New Efficient Format
        </div>
        
        <div class="stats">
            <h2>Test Configuration</h2>
            <div id="config-info">
                <div>🇺🇸 English: "Turn it up" (~1.2s)</div>
                <div>🇪🇸 Spanish: "Más fuerte" (~1.3s)</div>
                <div>🇨🇳 Chinese: "加强" (~1.1s)</div>
                <div>⚡ Expected: All commands should increase motor PWM</div>
            </div>
        </div>
        
        <button class="button" onclick="runRealApiTests()" id="runAllBtn">🚀 Test Real API (All Languages)</button>
        <button class="button" onclick="testSingleLanguage('english')" id="testEnBtn">🇺🇸 Test English</button>
        <button class="button" onclick="testSingleLanguage('spanish')" id="testEsBtn">🇪🇸 Test Spanish</button>
        <button class="button" onclick="testSingleLanguage('chinese')" id="testZhBtn">🇨🇳 Test Chinese</button>
        <button class="button" onclick="testApiConnectivity()" id="testConnBtn">🔧 Test API Connectivity</button>
        <button class="button" onclick="testWithMicrophone()" id="testMicBtn">🎤 Test with Real Microphone</button>
        <button class="button" onclick="testLLMOnly()" id="testLLMBtn">🤖 Test LLM Only</button>
        <button class="button" onclick="clearOutput()">🗑️ Clear Output</button>
        
        <div id="test-output" class="test-output">
Ready to test real API...\n\nClick "Test Real API" to start testing with actual Google Speech-to-Text and Gemini LLM.

⚠️  Note: This will make real API calls to Firebase functions.
        </div>
        
        <div id="test-stats" class="stats" style="display: none;">
            <h2>📊 Real API Test Results</h2>
            <div id="stats-content"></div>
        </div>
    </div>

    <script>
        const API_URL = 'https://speechtotextwithllm-qveg3gkwxa-ew.a.run.app';
        
        // Test output management
        function log(message, type = 'info') {
            const output = document.getElementById('test-output');
            const timestamp = new Date().toLocaleTimeString();
            const colorClass = type === 'error' ? 'error' : type === 'success' ? 'success' : type === 'warning' ? 'warning' : 'info';
            output.innerHTML += `<span class="${colorClass}">[${timestamp}] ${message}</span>\n`;
            output.scrollTop = output.scrollHeight;
        }
        
        function clearOutput() {
            document.getElementById('test-output').innerHTML = 'Output cleared.\n';
            document.getElementById('test-stats').style.display = 'none';
        }
        
        function setButtonsEnabled(enabled) {
            const buttons = ['runAllBtn', 'testEnBtn', 'testEsBtn', 'testZhBtn', 'testConnBtn', 'testMicBtn', 'testLLMBtn'];
            buttons.forEach(id => {
                document.getElementById(id).disabled = !enabled;
            });
        }
        
        // Test API connectivity with minimal request
        async function testApiConnectivity() {
            setButtonsEnabled(false);
            
            log(`\n🔧 Testing API Connectivity...`);
            log(`📡 Endpoint: ${API_URL}`);
            
            try {
                // Test with minimal valid request
                const testRequest = {
                    msgHis: [],
                    audioBuffer: [0, 100, 0, -100, 0], // Minimal test audio
                    currentPwm: 100,
                    encoding: 'LINEAR16',
                    sampleRateHertz: 16000,
                    languageCode: 'en-US'
                };
                
                log(`📦 Sending minimal test request...`);
                
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(testRequest)
                });
                
                log(`📊 Response Status: ${response.status} ${response.statusText}`);
                
                if (response.ok) {
                    const result = await response.json();
                    log(`✅ API is responding!`, 'success');
                    log(`📄 Response structure: ${JSON.stringify(Object.keys(result))}`);
                    log(`🔍 Success field: ${result.success}`);
                    log(`🔍 Error field: ${result.error || 'none'}`);
                } else {
                    const errorText = await response.text();
                    log(`❌ API error: ${errorText}`, 'error');
                }
                
            } catch (error) {
                log(`❌ Connection failed: ${error.message}`, 'error');
            } finally {
                setButtonsEnabled(true);
            }
        }
        
        // Test with real microphone input
        async function testWithMicrophone() {
            setButtonsEnabled(false);
            
            log(`\n🎤 Testing with Real Microphone...`);
            
            try {
                // Request microphone access
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                log(`✅ Microphone access granted`, 'success');
                log(`🎙️ Please say a motor control command in any language:`, 'info');
                log(`   🇺🇸 English: "turn it up" / "make it stronger"`);
                log(`   🇪🇸 Spanish: "más fuerte" / "aumenta la potencia"`);
                log(`   🇨🇳 Chinese: "加强" / "增加功率"`);
                log(`   🌍 Or any motor control command in your language...`);
                
                // Create audio context and recorder
                const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(stream);
                const processor = audioContext.createScriptProcessor(4096, 1, 1);
                
                const audioData = [];
                let recording = true;
                
                processor.onaudioprocess = function(e) {
                    if (recording) {
                        const inputData = e.inputBuffer.getChannelData(0);
                        // Convert to Int16Array
                        for (let i = 0; i < inputData.length; i++) {
                            const sample = Math.max(-1, Math.min(1, inputData[i]));
                            audioData.push(Math.round(sample * 32767));
                        }
                    }
                };
                
                source.connect(processor);
                processor.connect(audioContext.destination);
                
                // Countdown for user
                let countdown = 3;
                const countdownInterval = setInterval(() => {
                    if (countdown > 0) {
                        log(`🎙️ Recording in ${countdown}...`);
                        countdown--;
                    } else {
                        log(`🔴 Recording now! Speak your command...`, 'success');
                        clearInterval(countdownInterval);
                    }
                }, 1000);
                
                // Record for 4 seconds (1 second countdown + 3 seconds recording)
                setTimeout(async () => {
                    recording = false;
                    stream.getTracks().forEach(track => track.stop());
                    processor.disconnect();
                    source.disconnect();
                    
                    log(`🎵 Recorded ${audioData.length} samples (${(audioData.length / 16000).toFixed(2)}s)`);
                    
                    // Test with recorded audio using auto language detection
                    try {
                        const result = await callRealApi(
                            audioData,
                            100,
                            [],
                            'auto', // Use auto-detection instead of hardcoded language
                            { language: 'Auto-detected', command: 'Real microphone input' }
                        );
                        
                        log(`\n📋 Real Microphone Test Results:`);
                        log(`   - Success: ${result.success ? '✅' : '❌'}`);
                        log(`   - Transcription: "${result.transcription || 'None'}"`);
                        log(`   - Detected Language: ${result.detectedLanguage || 'Unknown'}`);
                        log(`   - Confidence: ${result.confidence ? (result.confidence * 100).toFixed(1) + '%' : 'N/A'}`);
                        log(`   - Intent Detected: ${result.intentDetected ? '✅' : '❌'}`);
                        log(`   - PWM Change: ${result.previousPwm || 100} → ${result.newPwmValue || 100}`);
                        log(`   - Response: "${result.response || 'None'}"`);
                        
                        // Validate results
                        const hasTranscription = result.transcription && result.transcription.length > 0;
                        const hasLanguageDetection = result.detectedLanguage && result.detectedLanguage.length > 0;
                        const intentDetected = result.intentDetected;
                        const pwmChanged = result.newPwmValue !== (result.previousPwm || 100);
                        const overallSuccess = result.success && hasTranscription && intentDetected;
                        
                        log(`\n📊 Microphone Test Validation:`);
                        log(`   - Has transcription: ${hasTranscription ? '✅' : '❌'}`);
                        log(`   - Language detected: ${hasLanguageDetection ? '✅' : '❌'}`);
                        log(`   - Intent recognized: ${intentDetected ? '✅' : '❌'}`);
                        log(`   - PWM changed: ${pwmChanged ? '✅' : '❌'}`);
                        log(`   - Overall result: ${overallSuccess ? '✅ SUCCESS' : '❌ FAILED'}`, 
                            overallSuccess ? 'success' : 'error');
                        
                        if (!overallSuccess && hasTranscription) {
                            log(`\n💡 Tip: Try saying clearer motor control commands like:`, 'warning');
                            log(`   🇺🇸 "turn it up", "make it stronger", "increase power"`);
                            log(`   🇪🇸 "más fuerte", "aumenta la potencia"`);
                            log(`   🇨🇳 "加强", "增加功率", "开大一点"`);
                        }
                        
                    } catch (error) {
                        log(`❌ Real microphone test failed: ${error.message}`, 'error');
                    }
                    
                    setButtonsEnabled(true);
                }, 4000); // 1 second countdown + 3 seconds recording
                
            } catch (error) {
                log(`❌ Microphone access failed: ${error.message}`, 'error');
                setButtonsEnabled(true);
            }
        }
        
        // Test LLM processing only (bypass speech recognition)
        async function testLLMOnly() {
            setButtonsEnabled(false);
            
            log(`\n🤖 Testing LLM Processing Only...`);
            log(`This bypasses speech recognition and tests the motor control logic directly.`);
            
            const testCases = [
                { transcript: 'turn it up', language: 'English', expected: 'increase' },
                { transcript: 'más fuerte', language: 'Spanish', expected: 'increase' },
                { transcript: '加强', language: 'Chinese', expected: 'increase' }
            ];
            
            for (const testCase of testCases) {
                try {
                    log(`\n🧪 Testing "${testCase.transcript}" (${testCase.language})`);
                    
                    const testRequest = {
                        msgHis: [],
                        testMode: true, // Enable test mode
                        testTranscript: testCase.transcript, // Provide transcript directly
                        currentPwm: 100,
                        encoding: 'LINEAR16',
                        sampleRateHertz: 16000,
                        languageCode: testCase.language === 'English' ? 'en-US' : 
                                     testCase.language === 'Spanish' ? 'es-ES' : 'zh-CN'
                    };
                    
                    log(`📡 Sending test request with transcript: "${testCase.transcript}"`);
                    
                    const response = await fetch(API_URL, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(testRequest)
                    });
                    
                    log(`📊 Response Status: ${response.status} ${response.statusText}`);
                    
                    if (response.ok) {
                        const result = await response.json();
                        log(`✅ LLM test successful!`, 'success');
                        log(`🎤 Transcript: "${result.transcription}"`);
                        log(`🤖 Response: "${result.response}"`);
                        log(`⚡ PWM: ${result.previousPwm} → ${result.newPwmValue}`);
                        log(`🎯 Intent detected: ${result.intentDetected}`);
                        log(`📈 Confidence: ${(result.confidence * 100).toFixed(1)}%`);
                        
                        // Validate results
                        const pwmIncreased = result.newPwmValue > result.previousPwm;
                        const intentDetected = result.intentDetected;
                        const hasResponse = result.response && result.response.length > 0;
                        
                        log(`📋 Validation:`);
                        log(`   - Intent detected: ${intentDetected ? '✅' : '❌'}`);
                        log(`   - PWM increased: ${pwmIncreased ? '✅' : '❌'}`);
                        log(`   - Has response: ${hasResponse ? '✅' : '❌'}`);
                        log(`   - Overall: ${(intentDetected && pwmIncreased && hasResponse) ? '✅ SUCCESS' : '❌ FAILED'}`, 
                            (intentDetected && pwmIncreased && hasResponse) ? 'success' : 'error');
                        
                    } else {
                        const errorText = await response.text();
                        log(`❌ LLM test failed: ${errorText}`, 'error');
                    }
                    
                } catch (error) {
                    log(`❌ LLM test error: ${error.message}`, 'error');
                }
                
                // Small delay between tests
                await new Promise(resolve => setTimeout(resolve, 500));
            }
            
            log(`\n🏁 LLM-only testing completed!`, 'success');
            setButtonsEnabled(true);
        }
        
        // Generate test audio data - using white noise with speech-like characteristics
        function generateTestAudio(duration, language) {
            const sampleRate = 16000;
            const samples = Math.floor(duration * sampleRate);
            const audioData = new Array(samples);
            
            // Use more speech-like frequencies and patterns
            let baseFreq = 200; // Higher base frequency for better recognition
            let amplitude = 0.5; // Lower amplitude to avoid clipping
            
            switch (language) {
                case 'english':
                    baseFreq = 220; // A3 note
                    break;
                case 'spanish':
                    baseFreq = 196; // G3 note
                    break;
                case 'chinese':
                    baseFreq = 247; // B3 note
                    break;
            }
            
            for (let i = 0; i < samples; i++) {
                const t = i / sampleRate;
                
                // Create more realistic speech pattern with vowel-like formants
                let signal = 0;
                
                // Fundamental frequency
                signal += Math.sin(2 * Math.PI * baseFreq * t) * amplitude;
                
                // First formant (around 500-700 Hz for vowels)
                signal += Math.sin(2 * Math.PI * (baseFreq * 2.5) * t) * amplitude * 0.6;
                
                // Second formant (around 1000-1500 Hz for vowels)
                signal += Math.sin(2 * Math.PI * (baseFreq * 5) * t) * amplitude * 0.4;
                
                // Third formant (around 2000-3000 Hz)
                signal += Math.sin(2 * Math.PI * (baseFreq * 10) * t) * amplitude * 0.2;
                
                // Add speech-like modulation
                const modulation = 1 + 0.1 * Math.sin(2 * Math.PI * 5 * t); // 5 Hz modulation
                signal *= modulation;
                
                // Natural envelope with attack and decay
                let envelope = 1;
                const attackTime = 0.1; // 100ms attack
                const decayTime = 0.1;  // 100ms decay
                
                if (t < attackTime) {
                    envelope = t / attackTime;
                } else if (t > duration - decayTime) {
                    envelope = (duration - t) / decayTime;
                }
                
                signal *= envelope;
                
                // Add minimal noise for realism
                signal += (Math.random() - 0.5) * 0.05;
                
                // Convert to Int16 range with proper scaling
                audioData[i] = Math.max(-32768, Math.min(32767, Math.round(signal * 20000)));
            }
            
            // Validate audio data
            const minVal = Math.min(...audioData);
            const maxVal = Math.max(...audioData);
            const avgVal = audioData.reduce((a, b) => a + b, 0) / audioData.length;
            const rms = Math.sqrt(audioData.reduce((sum, val) => sum + val * val, 0) / audioData.length);
            
            console.log(`Generated ${language} audio: ${samples} samples, range: ${minVal} to ${maxVal}, avg: ${avgVal.toFixed(2)}, RMS: ${rms.toFixed(2)}`);
            
            return audioData;
        }
        
        // Test cases
        const testCases = [
            {
                language: 'English',
                command: 'Turn it up',
                expectedIntent: true,
                expectedPwmChange: 'increase',
                audioData: generateTestAudio(1.2, 'english'),
                languageCode: 'en-US'
            },
            {
                language: 'Spanish', 
                command: 'Más fuerte',
                expectedIntent: true,
                expectedPwmChange: 'increase',
                audioData: generateTestAudio(1.3, 'spanish'),
                languageCode: 'es-ES'
            },
            {
                language: 'Chinese',
                command: '加强',
                expectedIntent: true,
                expectedPwmChange: 'increase',
                audioData: generateTestAudio(1.1, 'chinese'),
                languageCode: 'zh-CN'
            }
        ];
        
        // Real API call
        async function callRealApi(audioBuffer, currentPwm, msgHis, languageCode, testCase) {
            log(`🔄 Calling real API for ${testCase.language} audio...`);
            log(`   - Audio buffer: ${audioBuffer.length} samples`);
            log(`   - Duration: ${(audioBuffer.length / 16000).toFixed(2)}s`);
            log(`   - Current PWM: ${currentPwm}`);
            log(`   - Language code: ${languageCode}`);
            
            try {
                log(`   📡 Making API request to: ${API_URL}`);
                
                const requestBody = {
                    msgHis: msgHis,
                    audioBuffer: audioBuffer, // Int16Array format
                    currentPwm: currentPwm,
                    encoding: 'LINEAR16',
                    sampleRateHertz: 16000,
                    languageCode: languageCode
                };
                
                log(`   📦 Request payload size: ${JSON.stringify(requestBody).length} bytes`);
                log(`   🔍 Request structure: msgHis=${requestBody.msgHis.length}, audioBuffer=${requestBody.audioBuffer.length}, currentPwm=${requestBody.currentPwm}, encoding=${requestBody.encoding}, sampleRate=${requestBody.sampleRateHertz}, lang=${requestBody.languageCode}`);
                
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(requestBody)
                });
                
                log(`   📊 API Response Status: ${response.status} ${response.statusText}`);
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`API error ${response.status}: ${errorText}`);
                }
                
                const result = await response.json();
                
                log(`   ✅ API call successful`, 'success');
                log(`   📄 Full response: ${JSON.stringify(result, null, 2)}`);
                log(`   🎤 Transcription: "${result.transcription || 'N/A'}"`);
                log(`   🤖 Response: "${result.response || 'N/A'}"`);
                log(`   ⚡ PWM: ${result.previousPwm || currentPwm} → ${result.newPwmValue || currentPwm}`);
                log(`   🎯 Intent detected: ${result.intentDetected || false}`);
                log(`   📈 Confidence: ${result.confidence ? (result.confidence * 100).toFixed(1) + '%' : 'N/A'}`);
                log(`   🌍 Detected language: ${result.detectedLanguage || 'N/A'}`);
                
                return result;
                
            } catch (error) {
                log(`   ❌ API call failed: ${error.message}`, 'error');
                throw error;
            }
        }
        
        // Test single language
        async function testSingleLanguage(languageFilter) {
            const testCase = testCases.find(tc => tc.language.toLowerCase() === languageFilter);
            if (!testCase) {
                log(`❌ Test case not found for language: ${languageFilter}`, 'error');
                return;
            }
            
            setButtonsEnabled(false);
            
            log(`\n${'='.repeat(50)}`);
            log(`🧪 Testing ${testCase.language} Command: "${testCase.command}"`);
            log(`${'='.repeat(50)}`);
            
            const currentPwm = 100;
            const messageHistory = [];
            
            try {
                const result = await callRealApi(
                    testCase.audioData,
                    currentPwm,
                    messageHistory,
                    testCase.languageCode,
                    testCase
                );
                
                // Validate results
                const hasTranscription = result.transcription && result.transcription.length > 0;
                const hasResponse = result.response && result.response.length > 0;
                const pwmIncreased = result.newPwmValue > result.previousPwm;
                const intentMatches = result.intentDetected === testCase.expectedIntent;
                const pwmChangeMatches = (testCase.expectedPwmChange === 'increase') === pwmIncreased;
                const hasConfidence = result.confidence !== undefined && result.confidence > 0;
                const overallSuccess = result.success && hasTranscription && intentMatches && pwmChangeMatches;
                
                log(`\n📋 Validation Results:`);
                log(`   - API success: ${result.success ? '✅ PASS' : '❌ FAIL'}`);
                log(`   - Has transcription: ${hasTranscription ? '✅ PASS' : '❌ FAIL'}`);
                log(`   - Has response: ${hasResponse ? '✅ PASS' : '❌ FAIL'}`);
                log(`   - Has confidence: ${hasConfidence ? '✅ PASS' : '❌ FAIL'}`);
                log(`   - Intent detection: ${intentMatches ? '✅ PASS' : '❌ FAIL'}`);
                log(`   - PWM change direction: ${pwmChangeMatches ? '✅ PASS' : '❌ FAIL'}`);
                log(`   - Overall result: ${overallSuccess ? '✅ SUCCESS' : '❌ FAILED'}`, overallSuccess ? 'success' : 'error');
                
            } catch (error) {
                log(`❌ Test failed: ${error.message}`, 'error');
            } finally {
                setButtonsEnabled(true);
            }
        }
        
        // Test with real microphone input
        async function testWithMicrophone() {
            setButtonsEnabled(false);
            
            log(`\n🎤 Testing with Real Microphone...`);
            
            try {
                // Request microphone access
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                log(`✅ Microphone access granted`, 'success');
                log(`🎙️ Please say a motor control command in any language:`, 'info');
                log(`   🇺🇸 English: "turn it up" / "make it stronger"`);
                log(`   🇪🇸 Spanish: "más fuerte" / "aumenta la potencia"`);
                log(`   🇨🇳 Chinese: "加强" / "增加功率"`);
                log(`   🌍 Or any motor control command in your language...`);
                
                // Create audio context and recorder
                const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(stream);
                const processor = audioContext.createScriptProcessor(4096, 1, 1);
                
                const audioData = [];
                let recording = true;
                
                processor.onaudioprocess = function(e) {
                    if (recording) {
                        const inputData = e.inputBuffer.getChannelData(0);
                        // Convert to Int16Array
                        for (let i = 0; i < inputData.length; i++) {
                            const sample = Math.max(-1, Math.min(1, inputData[i]));
                            audioData.push(Math.round(sample * 32767));
                        }
                    }
                };
                
                source.connect(processor);
                processor.connect(audioContext.destination);
                
                // Countdown for user
                let countdown = 3;
                const countdownInterval = setInterval(() => {
                    if (countdown > 0) {
                        log(`🎙️ Recording in ${countdown}...`);
                        countdown--;
                    } else {
                        log(`🔴 Recording now! Speak your command...`, 'success');
                        clearInterval(countdownInterval);
                    }
                }, 1000);
                
                // Record for 4 seconds (1 second countdown + 3 seconds recording)
                setTimeout(async () => {
                    recording = false;
                    stream.getTracks().forEach(track => track.stop());
                    processor.disconnect();
                    source.disconnect();
                    
                    log(`🎵 Recorded ${audioData.length} samples (${(audioData.length / 16000).toFixed(2)}s)`);
                    
                    // Test with recorded audio using auto language detection
                    try {
                        const result = await callRealApi(
                            audioData,
                            100,
                            [],
                            'auto', // Use auto-detection instead of hardcoded language
                            { language: 'Auto-detected', command: 'Real microphone input' }
                        );
                        
                        log(`\n📋 Real Microphone Test Results:`);
                        log(`   - Success: ${result.success ? '✅' : '❌'}`);
                        log(`   - Transcription: "${result.transcription || 'None'}"`);
                        log(`   - Detected Language: ${result.detectedLanguage || 'Unknown'}`);
                        log(`   - Confidence: ${result.confidence ? (result.confidence * 100).toFixed(1) + '%' : 'N/A'}`);
                        log(`   - Intent Detected: ${result.intentDetected ? '✅' : '❌'}`);
                        log(`   - PWM Change: ${result.previousPwm || 100} → ${result.newPwmValue || 100}`);
                        log(`   - Response: "${result.response || 'None'}"`);
                        
                        // Validate results
                        const hasTranscription = result.transcription && result.transcription.length > 0;
                        const hasLanguageDetection = result.detectedLanguage && result.detectedLanguage.length > 0;
                        const intentDetected = result.intentDetected;
                        const pwmChanged = result.newPwmValue !== (result.previousPwm || 100);
                        const overallSuccess = result.success && hasTranscription && intentDetected;
                        
                        log(`\n📊 Microphone Test Validation:`);
                        log(`   - Has transcription: ${hasTranscription ? '✅' : '❌'}`);
                        log(`   - Language detected: ${hasLanguageDetection ? '✅' : '❌'}`);
                        log(`   - Intent recognized: ${intentDetected ? '✅' : '❌'}`);
                        log(`   - PWM changed: ${pwmChanged ? '✅' : '❌'}`);
                        log(`   - Overall result: ${overallSuccess ? '✅ SUCCESS' : '❌ FAILED'}`, 
                            overallSuccess ? 'success' : 'error');
                        
                        if (!overallSuccess && hasTranscription) {
                            log(`\n💡 Tip: Try saying clearer motor control commands like:`, 'warning');
                            log(`   🇺🇸 "turn it up", "make it stronger", "increase power"`);
                            log(`   🇪🇸 "más fuerte", "aumenta la potencia"`);
                            log(`   🇨🇳 "加强", "增加功率", "开大一点"`);
                        }
                        
                    } catch (error) {
                        log(`❌ Real microphone test failed: ${error.message}`, 'error');
                    }
                    
                    setButtonsEnabled(true);
                }, 4000); // 1 second countdown + 3 seconds recording
                
            } catch (error) {
                log(`❌ Microphone access failed: ${error.message}`, 'error');
                setButtonsEnabled(true);
            }
        }
        
        // Test LLM processing only (bypass speech recognition)
        async function testLLMOnly() {
            setButtonsEnabled(false);
            
            log(`\n🤖 Testing LLM Processing Only...`);
            log(`This bypasses speech recognition and tests the motor control logic directly.`);
            
            const testCases = [
                { transcript: 'turn it up', language: 'English', expected: 'increase' },
                { transcript: 'más fuerte', language: 'Spanish', expected: 'increase' },
                { transcript: '加强', language: 'Chinese', expected: 'increase' }
            ];
            
            for (const testCase of testCases) {
                try {
                    log(`\n🧪 Testing "${testCase.transcript}" (${testCase.language})`);
                    
                    const testRequest = {
                        msgHis: [],
                        testMode: true, // Enable test mode
                        testTranscript: testCase.transcript, // Provide transcript directly
                        currentPwm: 100,
                        encoding: 'LINEAR16',
                        sampleRateHertz: 16000,
                        languageCode: testCase.language === 'English' ? 'en-US' : 
                                     testCase.language === 'Spanish' ? 'es-ES' : 'zh-CN'
                    };
                    
                    log(`📡 Sending test request with transcript: "${testCase.transcript}"`);
                    
                    const response = await fetch(API_URL, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(testRequest)
                    });
                    
                    log(`📊 Response Status: ${response.status} ${response.statusText}`);
                    
                    if (response.ok) {
                        const result = await response.json();
                        log(`✅ LLM test successful!`, 'success');
                        log(`🎤 Transcript: "${result.transcription}"`);
                        log(`🤖 Response: "${result.response}"`);
                        log(`⚡ PWM: ${result.previousPwm} → ${result.newPwmValue}`);
                        log(`🎯 Intent detected: ${result.intentDetected}`);
                        log(`📈 Confidence: ${(result.confidence * 100).toFixed(1)}%`);
                        
                        // Validate results
                        const pwmIncreased = result.newPwmValue > result.previousPwm;
                        const intentDetected = result.intentDetected;
                        const hasResponse = result.response && result.response.length > 0;
                        
                        log(`📋 Validation:`);
                        log(`   - Intent detected: ${intentDetected ? '✅' : '❌'}`);
                        log(`   - PWM increased: ${pwmIncreased ? '✅' : '❌'}`);
                        log(`   - Has response: ${hasResponse ? '✅' : '❌'}`);
                        log(`   - Overall: ${(intentDetected && pwmIncreased && hasResponse) ? '✅ SUCCESS' : '❌ FAILED'}`, 
                            (intentDetected && pwmIncreased && hasResponse) ? 'success' : 'error');
                        
                    } else {
                        const errorText = await response.text();
                        log(`❌ LLM test failed: ${errorText}`, 'error');
                    }
                    
                } catch (error) {
                    log(`❌ LLM test error: ${error.message}`, 'error');
                }
                
                // Small delay between tests
                await new Promise(resolve => setTimeout(resolve, 500));
            }
            
            log(`\n🏁 LLM-only testing completed!`, 'success');
            setButtonsEnabled(true);
        }
        
        // Run all tests
        async function runRealApiTests() {
            setButtonsEnabled(false);
            
            log('🚀 Starting Real API Tests with Multi-language Motor Commands\n');
            log('=' * 60);
            
            let currentPwm = 100;
            let messageHistory = [];
            let testResults = [];
            
            log(`📊 Initial state: PWM = ${currentPwm}, Message history = ${messageHistory.length} items\n`);
            
            for (let i = 0; i < testCases.length; i++) {
                const testCase = testCases[i];
                
                log(`\n${'='.repeat(50)}`);
                log(`🧪 TEST ${i + 1}: ${testCase.language} Command`);
                log(`${'='.repeat(50)}`);
                log(`Command: "${testCase.command}"`);
                log(`Expected: ${testCase.expectedPwmChange} motor power`);
                log(`Audio samples: ${testCase.audioData.length}`);
                log(`Duration: ${(testCase.audioData.length / 16000).toFixed(2)}s`);
                
                try {
                    const result = await callRealApi(
                        testCase.audioData,
                        currentPwm,
                        messageHistory,
                        testCase.languageCode,
                        testCase
                    );
                    
                    // Validate results
                    const hasTranscription = result.transcription && result.transcription.length > 0;
                    const hasResponse = result.response && result.response.length > 0;
                    const pwmIncreased = result.newPwmValue > result.previousPwm;
                    const intentMatches = result.intentDetected === testCase.expectedIntent;
                    const pwmChangeMatches = (testCase.expectedPwmChange === 'increase') === pwmIncreased;
                    const hasConfidence = result.confidence !== undefined && result.confidence > 0;
                    const overallSuccess = result.success && hasTranscription && intentMatches && pwmChangeMatches;
                    
                    log(`\n📋 Validation Results:`);
                    log(`   - API success: ${result.success ? '✅ PASS' : '❌ FAIL'}`);
                    log(`   - Has transcription: ${hasTranscription ? '✅ PASS' : '❌ FAIL'}`);
                    log(`   - Has response: ${hasResponse ? '✅ PASS' : '❌ FAIL'}`);
                    log(`   - Has confidence: ${hasConfidence ? '✅ PASS' : '❌ FAIL'}`);
                    log(`   - Intent detection: ${intentMatches ? '✅ PASS' : '❌ FAIL'}`);
                    log(`   - PWM change direction: ${pwmChangeMatches ? '✅ PASS' : '❌ FAIL'}`);
                    log(`   - Overall result: ${overallSuccess ? '✅ SUCCESS' : '❌ FAILED'}`, overallSuccess ? 'success' : 'error');
                    
                    // Update state for next test
                    currentPwm = result.newPwmValue || currentPwm;
                    messageHistory = result.msgHis || messageHistory;
                    
                    testResults.push({
                        testCase: testCase,
                        result: result,
                        validation: {
                            hasTranscription,
                            hasResponse,
                            intentMatches,
                            pwmChangeMatches,
                            hasConfidence,
                            overall: overallSuccess
                        }
                    });
                    
                } catch (error) {
                    log(`❌ Test ${i + 1} failed with error: ${error.message}`, 'error');
                    testResults.push({
                        testCase: testCase,
                        error: error.message,
                        validation: { overall: false }
                    });
                }
                
                // Add delay between tests
                await new Promise(resolve => setTimeout(resolve, 1000));
            }
            
            // Final summary
            log(`\n${'='.repeat(60)}`);
            log(`📊 FINAL REAL API TEST SUMMARY`);
            log(`${'='.repeat(60)}`);
            
            const passedTests = testResults.filter(r => r.validation && r.validation.overall).length;
            const totalTests = testResults.length;
            
            log(`Tests passed: ${passedTests}/${totalTests}`, passedTests === totalTests ? 'success' : 'warning');
            log(`Success rate: ${((passedTests / totalTests) * 100).toFixed(1)}%`);
            log(`Final PWM value: ${currentPwm}`);
            log(`Message history length: ${messageHistory.length}`);
            
            testResults.forEach((result, index) => {
                const status = result.validation && result.validation.overall ? '✅' : '❌';
                const type = result.validation && result.validation.overall ? 'success' : 'error';
                log(`${status} Test ${index + 1} (${result.testCase.language}): ${result.testCase.command}`, type);
            });
            
            log(`\n🔧 Real API Pipeline Verification:`);
            log(`   ✅ Audio data generation: Working`);
            log(`   ✅ Int16Array transmission: Working`);
            log(`   ${passedTests > 0 ? '✅' : '❌'} Real Google Speech-to-Text API: ${passedTests > 0 ? 'Working' : 'Check API'}`);
            log(`   ${passedTests > 0 ? '✅' : '❌'} Real Google Gemini LLM API: ${passedTests > 0 ? 'Working' : 'Check API'}`);
            log(`   ✅ PWM control logic: Working`);
            log(`   ${passedTests === totalTests ? '✅' : '⚠️'} Multi-language support: ${passedTests === totalTests ? 'Working' : 'Partial'}`);
            
            log(`\n🏁 Real API test completed!`, 'success');
            log(`💡 ${passedTests === totalTests ? 'All systems operational!' : 'Some issues detected - check logs above.'}`, passedTests === totalTests ? 'success' : 'warning');
            
            // Show stats
            showTestStats(testResults, passedTests, totalTests, currentPwm, messageHistory.length);
            
            setButtonsEnabled(true);
        }
        
        function showTestStats(results, passed, total, finalPwm, historyLength) {
            const statsDiv = document.getElementById('test-stats');
            const statsContent = document.getElementById('stats-content');
            
            statsContent.innerHTML = `
                <div>✅ Tests Passed: ${passed}/${total}</div>
                <div>📈 Success Rate: ${((passed / total) * 100).toFixed(1)}%</div>
                <div>⚡ Final PWM: ${finalPwm}</div>
                <div>💬 Message History: ${historyLength} items</div>
                <div>🌍 Languages Tested: English, Spanish, Chinese</div>
                <div>🎯 Real APIs: Google Speech-to-Text + Gemini LLM</div>
                <div>🔗 Endpoint: speechtotextwithllm-qveg3gkwxa-ew.a.run.app</div>
            `;
            
            statsDiv.style.display = 'block';
        }
        
        // Initialize
        log('🧪 Real API Test Runner Initialized', 'success');
        log('Ready to test with actual Google APIs!');
        log('⚠️  Note: This will make real API calls and may incur costs.');
    </script>
</body>
</html>