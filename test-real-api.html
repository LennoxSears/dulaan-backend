<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real API Test Runner</title>
    <style>
        body {
            font-family: 'Courier New', monospace;
            background: #1a1a1a;
            color: #00ff00;
            padding: 20px;
            line-height: 1.4;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .test-output {
            background: #000;
            border: 1px solid #333;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
            white-space: pre-wrap;
            font-size: 14px;
            max-height: 600px;
            overflow-y: auto;
        }
        .button {
            background: #333;
            color: #00ff00;
            border: 1px solid #555;
            padding: 10px 20px;
            cursor: pointer;
            margin: 10px 5px;
            border-radius: 3px;
        }
        .button:hover {
            background: #555;
        }
        .button:disabled {
            background: #222;
            color: #666;
            cursor: not-allowed;
        }
        .success { color: #00ff00; }
        .error { color: #ff4444; }
        .warning { color: #ffaa00; }
        .info { color: #4488ff; }
        h1, h2 { color: #ffffff; }
        .stats {
            background: #222;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
        }
        .vad-status {
            background: #1a1a3a;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
            border-left: 3px solid #4488ff;
        }
        .vad-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
            background: #666;
        }
        .vad-indicator.listening {
            background: #00ff00;
            animation: pulse 1s infinite;
        }
        .vad-indicator.processing {
            background: #ffaa00;
            animation: spin 1s linear infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
        @keyframes spin {
            from { transform: rotate(0deg); }
            to { transform: rotate(360deg); }
        }
        .api-info {
            background: #1a3a1a;
            padding: 10px;
            border-radius: 3px;
            margin: 10px 0;
            border-left: 3px solid #00ff00;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Real API Test Runner</h1>
        <p>Testing actual Firebase speechToTextWithLLM function with multi-language audio samples</p>
        
        <div class="api-info">
            <strong>üîó API Endpoint:</strong> https://directaudiotopwm-qveg3gkwxa-ew.a.run.app<br>
            <strong>üéØ Test Type:</strong> Real Google Speech-to-Text + Gemini LLM<br>
            <strong>üìä Audio Format:</strong> Int16Array (LINEAR16 PCM, 16kHz) - New Efficient Format
        </div>
        
        <div class="stats">
            <h2>Test Configuration</h2>
            <div id="config-info">
                <div>üá∫üá∏ English: "Turn it up" (~1.2s)</div>
                <div>üá™üá∏ Spanish: "M√°s fuerte" (~1.3s)</div>
                <div>üá®üá≥ Chinese: "Âä†Âº∫" (~1.1s)</div>
                <div>‚ö° Expected: All commands should increase motor PWM</div>
            </div>
        </div>
        
        <button class="button" onclick="runRealApiTests()" id="runAllBtn">üöÄ Test Real API (All Languages)</button>
        <button class="button" onclick="testSingleLanguage('english')" id="testEnBtn">üá∫üá∏ Test English</button>
        <button class="button" onclick="testSingleLanguage('spanish')" id="testEsBtn">üá™üá∏ Test Spanish</button>
        <button class="button" onclick="testSingleLanguage('chinese')" id="testZhBtn">üá®üá≥ Test Chinese</button>
        <button class="button" onclick="testApiConnectivity()" id="testConnBtn">üîß Test API Connectivity</button>
        <button class="button" onclick="startOptimizedVoiceControl()" id="startVoiceBtn">üé§ Start Natural Voice Control (VAD)</button>
        <button class="button" onclick="stopOptimizedVoiceControl()" id="stopVoiceBtn" disabled>üîá Stop Voice Control</button>
        <button class="button" onclick="testLLMOnly()" id="testLLMBtn">ü§ñ Test LLM Only</button>
        <button class="button" onclick="clearOutput()">üóëÔ∏è Clear Output</button>
        
        <div id="test-output" class="test-output">
Ready to test real API...\n\nClick "Test Real API" to start testing with direct audio-to-PWM processing via Gemini 2.0.

‚ö†Ô∏è  Note: This will make real API calls to Firebase functions.
        </div>
        
        <div id="vad-status" class="vad-status" style="display: none;">
            <h2>üéôÔ∏è Optimized Voice Control Status</h2>
            <div id="vad-content">
                <div style="margin-bottom: 10px;">
                    <span id="vad-indicator" class="vad-indicator"></span>
                    <span id="vad-text" style="font-weight: bold;">Ready</span>
                </div>
                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px;">
                    <div>
                        <div><strong>üéõÔ∏è Motor Control:</strong></div>
                        <div>Current PWM: <span id="current-pwm" style="color: #00ff00; font-weight: bold;">100</span></div>
                        <div>Last Command: <span id="last-command">None</span></div>
                    </div>
                    <div>
                        <div><strong>üìä Efficiency Stats:</strong></div>
                        <div>API Reduction: <span id="efficiency-display" style="color: #00ff00; font-weight: bold;">0%</span></div>
                        <div>Chunks: <span id="total-chunks">0</span> | Calls: <span id="api-calls">0</span></div>
                    </div>
                </div>
                <div style="margin-top: 10px;">
                    <div><strong>üîä Audio Analysis:</strong></div>
                    <div>RMS Energy: <span id="rms-energy">0.000</span> | ZCR: <span id="zcr-rate">0.000</span></div>
                    <div>Speech Buffer: <span id="speech-buffer-size">0</span> samples | VAD Buffer: <span id="vad-buffer-size">0</span> samples</div>
                    <div>Audio Level: <span id="audio-level" style="color: #00ff00;">‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span></div>
                    <div>Speech Quality: <span id="speech-quality" style="color: #00ff00;">Excellent</span> | Voice Frames: <span id="voice-frames">0</span></div>
                </div>
            </div>
        </div>

        <div id="efficiency-comparison" class="stats" style="display: none;">
            <h2>üìà Efficiency Comparison</h2>
            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px;">
                <div style="background: #3a1a1a; padding: 15px; border-radius: 5px; border-left: 3px solid #ff4444;">
                    <h3 style="color: #ff4444; margin-top: 0;">‚ùå Traditional Streaming</h3>
                    <div>API Calls: <span id="traditional-calls">0</span></div>
                    <div>Bandwidth: <span id="traditional-bandwidth">0 KB</span></div>
                    <div>Efficiency: <span style="color: #ff4444;">0%</span></div>
                </div>
                <div style="background: #1a3a1a; padding: 15px; border-radius: 5px; border-left: 3px solid #00ff00;">
                    <h3 style="color: #00ff00; margin-top: 0;">‚úÖ Optimized VAD</h3>
                    <div>API Calls: <span id="optimized-calls">0</span></div>
                    <div>Bandwidth: <span id="optimized-bandwidth">0 KB</span></div>
                    <div>Efficiency: <span id="optimized-efficiency" style="color: #00ff00;">0%</span></div>
                </div>
            </div>
            <div style="margin-top: 15px; text-align: center;">
                <strong>üí∞ Cost Savings: <span id="cost-savings" style="color: #00ff00;">$0.00</span> per hour</strong>
            </div>
        </div>

        <div id="test-stats" class="stats" style="display: none;">
            <h2>üìä Real API Test Results</h2>
            <div id="stats-content"></div>
        </div>
    </div>

    <script>
        const API_URL = 'https://directaudiotopwm-qveg3gkwxa-ew.a.run.app';
        
        // Ring Buffer implementation for efficient audio buffering
        class RingBuffer {
            constructor(capacity) {
                this.capacity = capacity;
                this.buffer = new Float32Array(capacity);
                this.writeIndex = 0;
                this.count = 0;
            }

            push(data) {
                if (Array.isArray(data) || data instanceof Float32Array || data instanceof Int16Array) {
                    for (let i = 0; i < data.length; i++) {
                        this.pushSingle(data[i]);
                    }
                } else {
                    this.pushSingle(data);
                }
            }

            pushSingle(value) {
                this.buffer[this.writeIndex] = value;
                this.writeIndex = (this.writeIndex + 1) % this.capacity;
                this.count = Math.min(this.count + 1, this.capacity);
            }

            readLast(samples) {
                const result = new Float32Array(Math.min(samples, this.count));
                let readIndex = (this.writeIndex - Math.min(samples, this.count) + this.capacity) % this.capacity;
                
                for (let i = 0; i < result.length; i++) {
                    result[i] = this.buffer[readIndex];
                    readIndex = (readIndex + 1) % this.capacity;
                }
                
                return result;
            }

            readAll() {
                return this.readLast(this.count);
            }

            reset() {
                this.writeIndex = 0;
                this.count = 0;
            }
        }
        
        // Test output management
        function log(message, type = 'info') {
            const output = document.getElementById('test-output');
            const timestamp = new Date().toLocaleTimeString();
            const colorClass = type === 'error' ? 'error' : type === 'success' ? 'success' : type === 'warning' ? 'warning' : 'info';
            output.innerHTML += `<span class="${colorClass}">[${timestamp}] ${message}</span>\n`;
            output.scrollTop = output.scrollHeight;
        }
        
        function clearOutput() {
            document.getElementById('test-output').innerHTML = 'Output cleared.\n';
            document.getElementById('test-stats').style.display = 'none';
        }
        
        function setButtonsEnabled(enabled) {
            const buttons = ['runAllBtn', 'testEnBtn', 'testEsBtn', 'testZhBtn', 'testConnBtn', 'startVoiceBtn', 'testLLMBtn'];
            buttons.forEach(id => {
                document.getElementById(id).disabled = !enabled;
            });
        }

        // Optimized VAD System with Ring Buffers
        class OptimizedVADProcessor {
            constructor() {
                this.isActive = false;
                this.isListening = false;
                this.isProcessing = false;
                this.currentPwm = 100;
                
                // Ring buffers for efficient memory usage (increased for longer speech)
                this.vadBuffer = new RingBuffer(4800); // 300ms for VAD analysis (better context)
                this.speechBuffer = new RingBuffer(16000 * 30); // 30 seconds max speech (much longer)
                
                // VAD state
                this.consecutiveVoiceFrames = 0;
                this.consecutiveSilenceFrames = 0;
                this.isVoiceActive = false;
                this.voiceStartTime = 0;
                
                // Efficiency tracking
                this.totalChunks = 0;
                this.apiCalls = 0;
                this.lastRMS = 0;
                this.lastZeroCrossings = 0;
                
                // Audio processing
                this.audioContext = null;
                this.mediaStream = null;
                this.processor = null;
                
                // Optimized thresholds for best accuracy
                this.VAD_ENERGY_THRESHOLD = 0.008; // Balanced threshold - not too sensitive to noise
                this.VAD_ZCR_THRESHOLD = 0.08; // Balanced ZCR threshold
                this.VAD_VOICE_FRAMES = 3; // 3 consecutive frames to confirm voice (reduce false positives)
                this.VAD_SILENCE_FRAMES = 20; // 20 frames of silence to end speech (1.25 seconds)
                this.MIN_SPEECH_DURATION = 6400; // 400ms minimum (in samples) - shorter for quick commands
                this.MAX_SPEECH_DURATION = 320000; // 20 seconds maximum (much longer for complex speech)
            }

            async start() {
                try {
                    log("üé§ Starting optimized voice control with VAD...", 'info');
                    
                    // Request microphone access
                    this.mediaStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        }
                    });
                    
                    // Create audio context
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                    const source = this.audioContext.createMediaStreamSource(this.mediaStream);
                    this.processor = this.audioContext.createScriptProcessor(1024, 1, 1);
                    
                    // Process audio chunks
                    this.processor.onaudioprocess = (e) => {
                        if (this.isActive) {
                            this.processAudioChunk(e.inputBuffer.getChannelData(0));
                        }
                    };
                    
                    source.connect(this.processor);
                    this.processor.connect(this.audioContext.destination);
                    
                    this.isActive = true;
                    this.updateVADStatus('Ready - speak naturally', false, false);
                    
                    log("‚úÖ Voice control started! Speak naturally - no buttons needed.", 'success');
                    log("üéØ Say commands like: 'turn it up', 'm√°s fuerte', 'Âä†Âº∫'", 'info');
                    
                    document.getElementById('vad-status').style.display = 'block';
                    document.getElementById('efficiency-comparison').style.display = 'block';
                    document.getElementById('startVoiceBtn').disabled = true;
                    document.getElementById('stopVoiceBtn').disabled = false;
                    
                    return true;
                    
                } catch (error) {
                    log(`‚ùå Failed to start voice control: ${error.message}`, 'error');
                    return false;
                }
            }

            stop() {
                log("üîá Stopping voice control...", 'info');
                
                this.isActive = false;
                this.isListening = false;
                this.isProcessing = false;
                
                if (this.mediaStream) {
                    this.mediaStream.getTracks().forEach(track => track.stop());
                    this.mediaStream = null;
                }
                
                if (this.processor) {
                    this.processor.disconnect();
                    this.processor = null;
                }
                
                if (this.audioContext) {
                    this.audioContext.close();
                    this.audioContext = null;
                }
                
                this.updateVADStatus('Stopped', false, false);
                
                document.getElementById('startVoiceBtn').disabled = false;
                document.getElementById('stopVoiceBtn').disabled = true;
                
                log("‚úÖ Voice control stopped", 'success');
            }

            processAudioChunk(audioData) {
                this.totalChunks++;
                
                // Always buffer audio for pre/post-speech context (smart buffering)
                this.vadBuffer.push(audioData);
                
                // Advanced Voice Activity Detection
                const isVoiceActive = this.detectVoiceActivity(audioData);
                
                if (isVoiceActive) {
                    this.consecutiveVoiceFrames++;
                    this.consecutiveSilenceFrames = 0;
                    
                    // Voice start detection
                    if (!this.isVoiceActive && this.consecutiveVoiceFrames >= this.VAD_VOICE_FRAMES) {
                        this.handleVoiceStart();
                    }
                    
                    // Buffer speech audio during active speech
                    if (this.isVoiceActive) {
                        this.speechBuffer.push(audioData);
                        this.checkSpeechBufferLimits();
                    }
                    
                } else {
                    this.consecutiveSilenceFrames++;
                    this.consecutiveVoiceFrames = 0;
                    
                    // Voice end detection
                    if (this.isVoiceActive && this.consecutiveSilenceFrames >= this.VAD_SILENCE_FRAMES) {
                        this.handleVoiceEnd();
                    }
                }
                
                // Update efficiency display
                this.updateEfficiencyDisplay();
                
                // Visual feedback for audio processing
                if (this.totalChunks % 10 === 0) {
                    const indicator = document.getElementById('vad-indicator');
                    if (isVoiceActive) {
                        indicator.style.backgroundColor = '#00ff00'; // Green for voice
                    } else {
                        indicator.style.backgroundColor = '#666'; // Gray for silence
                    }
                }
            }

            detectVoiceActivity(audioData) {
                // Calculate RMS energy
                const rms = this.calculateRMS(audioData);
                this.lastRMS = rms;
                
                // Calculate zero crossing rate
                const zcr = this.calculateZeroCrossingRate(audioData);
                this.lastZeroCrossings = zcr;
                
                // Advanced VAD decision with adaptive thresholds
                const energyActive = rms > this.VAD_ENERGY_THRESHOLD;
                const zcrActive = zcr > this.VAD_ZCR_THRESHOLD && zcr < 0.5; // ZCR too high = noise
                
                // Adaptive threshold based on recent energy history
                if (!this.energyHistory) this.energyHistory = [];
                this.energyHistory.push(rms);
                if (this.energyHistory.length > 100) this.energyHistory.shift();
                
                const avgEnergy = this.energyHistory.reduce((a, b) => a + b, 0) / this.energyHistory.length;
                const adaptiveThreshold = Math.max(this.VAD_ENERGY_THRESHOLD, avgEnergy * 2);
                const adaptiveEnergyActive = rms > adaptiveThreshold;
                
                // Combined decision: energy must be active, ZCR should be reasonable
                const voiceDetected = energyActive && (zcrActive || rms > adaptiveThreshold * 1.5);
                
                // Debug logging (every 50 chunks to avoid spam)
                if (this.totalChunks % 50 === 0) {
                    console.log(`[VAD] RMS: ${rms.toFixed(4)} (>${this.VAD_ENERGY_THRESHOLD}=${energyActive}, adaptive>${adaptiveThreshold.toFixed(4)}=${adaptiveEnergyActive}) | ZCR: ${zcr.toFixed(4)} (${this.VAD_ZCR_THRESHOLD}-0.5=${zcrActive}) | Voice: ${voiceDetected}`);
                }
                
                return voiceDetected;
            }

            calculateRMS(audioData) {
                let sum = 0;
                for (let i = 0; i < audioData.length; i++) {
                    sum += audioData[i] * audioData[i];
                }
                return Math.sqrt(sum / audioData.length);
            }

            calculateZeroCrossingRate(audioData) {
                let crossings = 0;
                for (let i = 1; i < audioData.length; i++) {
                    if ((audioData[i] >= 0) !== (audioData[i - 1] >= 0)) {
                        crossings++;
                    }
                }
                return crossings / audioData.length;
            }

            checkSpeechBufferLimits() {
                const speechDuration = Date.now() - this.voiceStartTime;
                const bufferSize = this.speechBuffer.count;
                const maxDurationMs = this.MAX_SPEECH_DURATION / 16000 * 1000;
                
                // Send if max duration reached or buffer is 85% full (leave room for post-speech)
                if (speechDuration >= maxDurationMs || bufferSize >= this.speechBuffer.capacity * 0.85) {
                    
                    log(`üì¶ Buffer limit reached - sending speech chunk (${(speechDuration/1000).toFixed(1)}s / ${(maxDurationMs/1000).toFixed(1)}s max, ${bufferSize} samples)`, 'warning');
                    this.processSpeech(false); // Not final
                    
                    // Keep larger overlap for continuity with longer speech
                    const overlapSize = Math.min(8000, bufferSize * 0.15); // 500ms overlap or 15% of buffer
                    const overlapData = this.speechBuffer.readLast(overlapSize);
                    this.speechBuffer.reset();
                    if (overlapData.length > 0) {
                        this.speechBuffer.push(overlapData);
                        log(`üîÑ Kept ${overlapSize} samples (${(overlapSize/16000*1000).toFixed(0)}ms) for continuity`, 'info');
                    }
                }
            }



            handleVoiceStart() {
                this.isVoiceActive = true;
                this.isListening = true;
                this.voiceStartTime = Date.now();
                
                // Smart buffering: Include pre-speech context for natural start
                this.speechBuffer.reset();
                
                // Add recent VAD buffer content as pre-speech context (last 300ms for better quality)
                const preSpeechSamples = Math.min(4800, this.vadBuffer.count); // 300ms at 16kHz
                if (preSpeechSamples > 0) {
                    const preSpeechData = this.vadBuffer.readLast(preSpeechSamples);
                    this.speechBuffer.push(preSpeechData);
                    log(`üéôÔ∏è Voice start - added ${preSpeechSamples} pre-speech samples (${(preSpeechSamples/16000*1000).toFixed(0)}ms)`, 'info');
                }
                
                this.updateVADStatus('Listening...', true, false);
                log("üéôÔ∏è Voice detected - listening...", 'info');
            }

            async handleVoiceEnd() {
                // Add small post-speech buffer for natural ending (100ms)
                const postSpeechDelay = 100;
                
                setTimeout(async () => {
                    this.isVoiceActive = false;
                    this.isListening = false;
                    const speechDuration = Date.now() - this.voiceStartTime;
                    
                    // Add recent VAD buffer as post-speech context (200ms for natural ending)
                    const postSpeechSamples = Math.min(3200, this.vadBuffer.count); // 200ms
                    if (postSpeechSamples > 0) {
                        const postSpeechData = this.vadBuffer.readLast(postSpeechSamples);
                        this.speechBuffer.push(postSpeechData);
                        log(`üîá Voice end - added ${postSpeechSamples} post-speech samples (${(postSpeechSamples/16000*1000).toFixed(0)}ms)`, 'info');
                    }
                    
                    log(`üîá Speech duration: ${speechDuration}ms, Buffer: ${this.speechBuffer.count} samples`);
                    
                    // Send speech to API if we have enough audio
                    if (this.speechBuffer.count >= this.MIN_SPEECH_DURATION) {
                        await this.processSpeech(true); // Mark as final
                    } else {
                        log("üîá Speech too short, discarding", 'warning');
                        this.speechBuffer.reset();
                        this.updateVADStatus('Ready - speak naturally', false, false);
                    }
                }, postSpeechDelay);
            }

            async processSpeech(isFinal = true) {
                this.isProcessing = true;
                this.apiCalls++;
                
                this.updateVADStatus('Processing speech...', false, true);
                
                try {
                    const speechData = this.speechBuffer.readAll();
                    if (speechData.length === 0) return null;

                    // Convert to Int16Array for API
                    const int16Data = new Int16Array(speechData.length);
                    for (let i = 0; i < speechData.length; i++) {
                        const scaled = Math.max(-1, Math.min(1, speechData[i])) * 32767;
                        int16Data[i] = Math.max(-32768, Math.min(32767, scaled));
                    }

                    const speechDuration = (speechData.length / 16000).toFixed(2);
                    log(`‚ö° Processing ${speechDuration}s of speech (API call #${this.apiCalls})`, 'info');
                    
                    // Call real API with speech data
                    const result = await callRealApi(
                        Array.from(int16Data),
                        this.currentPwm,
                        [],
                        'auto',
                        { language: 'Auto-detected', command: 'Natural voice input' }
                    );
                    
                    // Update PWM if changed
                    if (result.newPwmValue !== undefined) {
                        this.currentPwm = result.newPwmValue;
                        document.getElementById('current-pwm').textContent = this.currentPwm;
                    }
                    
                    // Log results
                    log(`‚úÖ Speech processed successfully!`, 'success');
                    log(`üé§ "${result.transcription || 'No transcription'}"`, 'info');
                    log(`ü§ñ "${result.response || 'No response'}"`, 'info');
                    log(`‚ö° PWM: ${result.previousPwm || this.currentPwm} ‚Üí ${result.newPwmValue || this.currentPwm}`, 'info');
                    
                    // Update last command display
                    if (result.transcription) {
                        document.getElementById('last-command').textContent = result.transcription;
                    }
                    
                    if (result.intentDetected) {
                        log(`üéØ Motor command detected and executed!`, 'success');
                    } else {
                        log(`üí¨ Conversational response (no motor action)`, 'info');
                    }

                    // Reset buffer after sending if final
                    if (isFinal) {
                        this.speechBuffer.reset();
                    }

                    return result;
                    
                } catch (error) {
                    log(`‚ùå Speech processing failed: ${error.message}`, 'error');
                    throw error;
                } finally {
                    this.isProcessing = false;
                    if (isFinal) {
                        this.updateVADStatus('Ready - speak naturally', false, false);
                    }
                }
            }

            updateVADStatus(text, listening, processing) {
                const indicator = document.getElementById('vad-indicator');
                const textElement = document.getElementById('vad-text');
                
                if (processing) {
                    indicator.className = 'vad-indicator processing';
                } else if (listening) {
                    indicator.className = 'vad-indicator listening';
                } else {
                    indicator.className = 'vad-indicator';
                }
                
                textElement.textContent = text;
            }

            updateEfficiencyComparison() {
                // Show comparison panel
                document.getElementById('efficiency-comparison').style.display = 'block';
                
                // Traditional approach would call API for every chunk
                const traditionalCalls = this.totalChunks;
                const optimizedCalls = this.apiCalls;
                
                // Estimate bandwidth (assuming 1KB per chunk for traditional, 10KB per speech segment for optimized)
                const traditionalBandwidth = (traditionalCalls * 1).toFixed(1);
                const optimizedBandwidth = (optimizedCalls * 10).toFixed(1);
                
                // Calculate efficiency
                const efficiency = this.totalChunks > 0 ? 
                    ((1 - this.apiCalls / this.totalChunks) * 100).toFixed(1) : 0;
                
                // Estimate cost savings (assuming $0.001 per API call)
                const costSavings = ((traditionalCalls - optimizedCalls) * 0.001 * 3600 / Math.max(1, this.totalChunks / 100)).toFixed(2);
                
                // Update display
                document.getElementById('traditional-calls').textContent = traditionalCalls;
                document.getElementById('traditional-bandwidth').textContent = traditionalBandwidth;
                document.getElementById('optimized-calls').textContent = optimizedCalls;
                document.getElementById('optimized-bandwidth').textContent = optimizedBandwidth;
                document.getElementById('optimized-efficiency').textContent = efficiency + '%';
                document.getElementById('cost-savings').textContent = '$' + costSavings;
            }

            updateEfficiencyDisplay() {
                const efficiency = this.totalChunks > 0 ? 
                    ((1 - this.apiCalls / this.totalChunks) * 100).toFixed(1) : 0;
                
                // Update efficiency stats
                document.getElementById('efficiency-display').textContent = efficiency + '%';
                document.getElementById('total-chunks').textContent = this.totalChunks;
                document.getElementById('api-calls').textContent = this.apiCalls;
                
                // Update audio analysis
                document.getElementById('rms-energy').textContent = this.lastRMS.toFixed(3);
                document.getElementById('zcr-rate').textContent = this.lastZeroCrossings.toFixed(3);
                document.getElementById('speech-buffer-size').textContent = this.speechBuffer.count;
                document.getElementById('vad-buffer-size').textContent = this.vadBuffer.count;
                
                // Update speech quality indicator
                const qualityElement = document.getElementById('speech-quality');
                const voiceFramesElement = document.getElementById('voice-frames');
                if (qualityElement && voiceFramesElement) {
                    voiceFramesElement.textContent = this.consecutiveVoiceFrames;
                    
                    if (this.lastRMS > 0.02) {
                        qualityElement.textContent = 'Excellent';
                        qualityElement.style.color = '#00ff00';
                    } else if (this.lastRMS > 0.01) {
                        qualityElement.textContent = 'Good';
                        qualityElement.style.color = '#88ff00';
                    } else if (this.lastRMS > 0.005) {
                        qualityElement.textContent = 'Fair';
                        qualityElement.style.color = '#ffaa00';
                    } else {
                        qualityElement.textContent = 'Poor';
                        qualityElement.style.color = '#ff4444';
                    }
                }
                
                // Update audio level meter with better scaling
                const levelMeter = document.getElementById('audio-level');
                if (levelMeter) {
                    // Logarithmic scaling for better visual representation
                    const dbLevel = 20 * Math.log10(Math.max(0.001, this.lastRMS)); // Convert to dB
                    const normalizedLevel = Math.max(0, Math.min(20, (dbLevel + 60) / 3)); // Scale -60dB to 0dB -> 0 to 20
                    const level = Math.floor(normalizedLevel);
                    
                    const bars = '‚ñà'.repeat(level) + '‚ñë'.repeat(20 - level);
                    levelMeter.textContent = bars;
                    
                    // Color coding: red=low, yellow=medium, green=good
                    if (level < 3) {
                        levelMeter.style.color = '#ff4444'; // Red - too quiet
                    } else if (level < 8) {
                        levelMeter.style.color = '#ffaa00'; // Orange - moderate
                    } else {
                        levelMeter.style.color = '#00ff00'; // Green - good level
                    }
                }
                
                // Color coding for efficiency
                const efficiencyElement = document.getElementById('efficiency-display');
                if (parseFloat(efficiency) > 90) {
                    efficiencyElement.style.color = '#00ff00'; // Green for excellent
                } else if (parseFloat(efficiency) > 70) {
                    efficiencyElement.style.color = '#ffaa00'; // Orange for good
                } else {
                    efficiencyElement.style.color = '#ff4444'; // Red for poor
                }
                
                // Update efficiency comparison
                this.updateEfficiencyComparison();
            }
        }

        // Global VAD processor instance
        let vadProcessor = null;

        // Start optimized voice control
        async function startOptimizedVoiceControl() {
            if (!vadProcessor) {
                vadProcessor = new OptimizedVADProcessor();
            }
            
            const success = await vadProcessor.start();
            if (success) {
                setButtonsEnabled(false);
                document.getElementById('stopVoiceBtn').disabled = false;
            }
        }

        // Stop optimized voice control
        function stopOptimizedVoiceControl() {
            if (vadProcessor) {
                vadProcessor.stop();
                setButtonsEnabled(true);
                document.getElementById('stopVoiceBtn').disabled = true;
            }
        }
        
        // Test API connectivity with minimal request
        async function testApiConnectivity() {
            setButtonsEnabled(false);
            
            log(`\nüîß Testing API Connectivity...`);
            log(`üì° Endpoint: ${API_URL}`);
            
            try {
                // Test with minimal valid request
                const testRequest = {
                    msgHis: [],
                    audioBuffer: [0, 100, 0, -100, 0], // Minimal test audio
                    currentPwm: 100,
                    encoding: 'LINEAR16',
                    sampleRateHertz: 16000,
                    languageCode: 'en-US'
                };
                
                log(`üì¶ Sending minimal test request...`);
                
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(testRequest)
                });
                
                log(`üìä Response Status: ${response.status} ${response.statusText}`);
                
                if (response.ok) {
                    const result = await response.json();
                    log(`‚úÖ API is responding!`, 'success');
                    log(`üìÑ Response structure: ${JSON.stringify(Object.keys(result))}`);
                    log(`üîç Success field: ${result.success}`);
                    log(`üîç Error field: ${result.error || 'none'}`);
                } else {
                    const errorText = await response.text();
                    log(`‚ùå API error: ${errorText}`, 'error');
                }
                
            } catch (error) {
                log(`‚ùå Connection failed: ${error.message}`, 'error');
            } finally {
                setButtonsEnabled(true);
            }
        }


        
        // Generate test audio data - using white noise with speech-like characteristics
        function generateTestAudio(duration, language) {
            const sampleRate = 16000;
            const samples = Math.floor(duration * sampleRate);
            const audioData = new Array(samples);
            
            // Use more speech-like frequencies and patterns
            let baseFreq = 200; // Higher base frequency for better recognition
            let amplitude = 0.5; // Lower amplitude to avoid clipping
            
            switch (language) {
                case 'english':
                    baseFreq = 220; // A3 note
                    break;
                case 'spanish':
                    baseFreq = 196; // G3 note
                    break;
                case 'chinese':
                    baseFreq = 247; // B3 note
                    break;
            }
            
            for (let i = 0; i < samples; i++) {
                const t = i / sampleRate;
                
                // Create more realistic speech pattern with vowel-like formants
                let signal = 0;
                
                // Fundamental frequency
                signal += Math.sin(2 * Math.PI * baseFreq * t) * amplitude;
                
                // First formant (around 500-700 Hz for vowels)
                signal += Math.sin(2 * Math.PI * (baseFreq * 2.5) * t) * amplitude * 0.6;
                
                // Second formant (around 1000-1500 Hz for vowels)
                signal += Math.sin(2 * Math.PI * (baseFreq * 5) * t) * amplitude * 0.4;
                
                // Third formant (around 2000-3000 Hz)
                signal += Math.sin(2 * Math.PI * (baseFreq * 10) * t) * amplitude * 0.2;
                
                // Add speech-like modulation
                const modulation = 1 + 0.1 * Math.sin(2 * Math.PI * 5 * t); // 5 Hz modulation
                signal *= modulation;
                
                // Natural envelope with attack and decay
                let envelope = 1;
                const attackTime = 0.1; // 100ms attack
                const decayTime = 0.1;  // 100ms decay
                
                if (t < attackTime) {
                    envelope = t / attackTime;
                } else if (t > duration - decayTime) {
                    envelope = (duration - t) / decayTime;
                }
                
                signal *= envelope;
                
                // Add minimal noise for realism
                signal += (Math.random() - 0.5) * 0.05;
                
                // Convert to Int16 range with proper scaling
                audioData[i] = Math.max(-32768, Math.min(32767, Math.round(signal * 20000)));
            }
            
            // Validate audio data
            const minVal = Math.min(...audioData);
            const maxVal = Math.max(...audioData);
            const avgVal = audioData.reduce((a, b) => a + b, 0) / audioData.length;
            const rms = Math.sqrt(audioData.reduce((sum, val) => sum + val * val, 0) / audioData.length);
            
            console.log(`Generated ${language} audio: ${samples} samples, range: ${minVal} to ${maxVal}, avg: ${avgVal.toFixed(2)}, RMS: ${rms.toFixed(2)}`);
            
            return audioData;
        }
        
        // Test cases
        const testCases = [
            {
                language: 'English',
                command: 'Turn it up',
                expectedIntent: true,
                expectedPwmChange: 'increase',
                audioData: generateTestAudio(1.2, 'english'),
                languageCode: 'en-US'
            },
            {
                language: 'Spanish', 
                command: 'M√°s fuerte',
                expectedIntent: true,
                expectedPwmChange: 'increase',
                audioData: generateTestAudio(1.3, 'spanish'),
                languageCode: 'es-ES'
            },
            {
                language: 'Chinese',
                command: 'Âä†Âº∫',
                expectedIntent: true,
                expectedPwmChange: 'increase',
                audioData: generateTestAudio(1.1, 'chinese'),
                languageCode: 'zh-CN'
            }
        ];
        
        // Test LLM processing only (bypass speech recognition)
        async function testLLMOnly() {
            setButtonsEnabled(false);
            
            log(`\nü§ñ Testing LLM Processing Only...`);
            log(`This bypasses speech recognition and tests the motor control logic directly.`);
            
            const testCases = [
                { transcript: 'turn it up', language: 'English', expected: 'increase' },
                { transcript: 'm√°s fuerte', language: 'Spanish', expected: 'increase' },
                { transcript: 'Âä†Âº∫', language: 'Chinese', expected: 'increase' }
            ];
            
            for (const testCase of testCases) {
                try {
                    log(`\nüß™ Testing "${testCase.transcript}" (${testCase.language})`);
                    
                    const testRequest = {
                        msgHis: [],
                        testMode: true, // Enable test mode
                        testTranscript: testCase.transcript, // Provide transcript directly
                        currentPwm: 100,
                        encoding: 'LINEAR16',
                        sampleRateHertz: 16000,
                        languageCode: testCase.language === 'English' ? 'en-US' : 
                                     testCase.language === 'Spanish' ? 'es-ES' : 'zh-CN'
                    };
                    
                    log(`üì° Sending test request with transcript: "${testCase.transcript}"`);
                    
                    const response = await fetch(API_URL, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(testRequest)
                    });
                    
                    log(`üìä Response Status: ${response.status} ${response.statusText}`);
                    
                    if (response.ok) {
                        const result = await response.json();
                        log(`‚úÖ LLM test successful!`, 'success');
                        log(`üé§ Transcript: "${result.transcription}"`);
                        log(`ü§ñ Response: "${result.response}"`);
                        log(`‚ö° PWM: ${result.previousPwm} ‚Üí ${result.newPwmValue}`);
                        log(`üéØ Intent detected: ${result.intentDetected}`);
                        log(`üìà Confidence: ${(result.confidence * 100).toFixed(1)}%`);
                        
                        // Validate results
                        const pwmIncreased = result.newPwmValue > result.previousPwm;
                        const intentDetected = result.intentDetected;
                        const hasResponse = result.response && result.response.length > 0;
                        
                        log(`üìã Validation:`);
                        log(`   - Intent detected: ${intentDetected ? '‚úÖ' : '‚ùå'}`);
                        log(`   - PWM increased: ${pwmIncreased ? '‚úÖ' : '‚ùå'}`);
                        log(`   - Has response: ${hasResponse ? '‚úÖ' : '‚ùå'}`);
                        log(`   - Overall: ${(intentDetected && pwmIncreased && hasResponse) ? '‚úÖ SUCCESS' : '‚ùå FAILED'}`, 
                            (intentDetected && pwmIncreased && hasResponse) ? 'success' : 'error');
                        
                    } else {
                        const errorText = await response.text();
                        log(`‚ùå LLM test failed: ${errorText}`, 'error');
                    }
                    
                } catch (error) {
                    log(`‚ùå LLM test error: ${error.message}`, 'error');
                }
                
                // Small delay between tests
                await new Promise(resolve => setTimeout(resolve, 500));
            }
            
            log(`\nüèÅ LLM-only testing completed!`, 'success');
            setButtonsEnabled(true);
        }
        
        // Real API call
        async function callRealApi(audioBuffer, currentPwm, msgHis, languageCode, testCase) {
            log(`üîÑ Calling real API for ${testCase.language} audio...`);
            log(`   - Audio buffer: ${audioBuffer.length} samples`);
            log(`   - Duration: ${(audioBuffer.length / 16000).toFixed(2)}s`);
            log(`   - Current PWM: ${currentPwm}`);
            log(`   - Language code: ${languageCode}`);
            
            try {
                log(`   üì° Making API request to: ${API_URL}`);
                
                const requestBody = {
                    msgHis: msgHis,
                    audioData: audioBuffer, // Int16Array format for direct audio API
                    currentPwm: currentPwm
                };
                
                log(`   üì¶ Request payload size: ${JSON.stringify(requestBody).length} bytes`);
                log(`   üîç Request structure: msgHis=${requestBody.msgHis.length}, audioData=${requestBody.audioData.length}, currentPwm=${requestBody.currentPwm}`);
                
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(requestBody)
                });
                
                log(`   üìä API Response Status: ${response.status} ${response.statusText}`);
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`API error ${response.status}: ${errorText}`);
                }
                
                const result = await response.json();
                
                log(`   ‚úÖ API call successful`, 'success');
                log(`   üìÑ Full response: ${JSON.stringify(result, null, 2)}`);
                log(`   üé§ Transcription: "${result.transcription || 'N/A'}"`);
                log(`   ü§ñ Response: "${result.response || 'N/A'}"`);
                log(`   ‚ö° PWM: ${result.previousPwm || currentPwm} ‚Üí ${result.newPwmValue || currentPwm}`);
                log(`   üéØ Intent detected: ${result.intentDetected || false}`);
                log(`   üìà Confidence: ${result.confidence ? (result.confidence * 100).toFixed(1) + '%' : 'N/A'}`);
                log(`   üåç Detected language: ${result.detectedLanguage || 'N/A'}`);
                
                return result;
                
            } catch (error) {
                log(`   ‚ùå API call failed: ${error.message}`, 'error');
                throw error;
            }
        }
        
        // Test single language
        async function testSingleLanguage(languageFilter) {
            const testCase = testCases.find(tc => tc.language.toLowerCase() === languageFilter);
            if (!testCase) {
                log(`‚ùå Test case not found for language: ${languageFilter}`, 'error');
                return;
            }
            
            setButtonsEnabled(false);
            
            log(`\n${'='.repeat(50)}`);
            log(`üß™ Testing ${testCase.language} Command: "${testCase.command}"`);
            log(`${'='.repeat(50)}`);
            
            const currentPwm = 100;
            const messageHistory = [];
            
            try {
                const result = await callRealApi(
                    testCase.audioData,
                    currentPwm,
                    messageHistory,
                    testCase.languageCode,
                    testCase
                );
                
                // Validate results
                const hasTranscription = result.transcription && result.transcription.length > 0;
                const hasResponse = result.response && result.response.length > 0;
                const pwmIncreased = result.newPwmValue > result.previousPwm;
                const intentMatches = result.intentDetected === testCase.expectedIntent;
                const pwmChangeMatches = (testCase.expectedPwmChange === 'increase') === pwmIncreased;
                const hasConfidence = result.confidence !== undefined && result.confidence > 0;
                const overallSuccess = result.success && hasTranscription && intentMatches && pwmChangeMatches;
                
                log(`\nüìã Validation Results:`);
                log(`   - API success: ${result.success ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                log(`   - Has transcription: ${hasTranscription ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                log(`   - Has response: ${hasResponse ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                log(`   - Has confidence: ${hasConfidence ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                log(`   - Intent detection: ${intentMatches ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                log(`   - PWM change direction: ${pwmChangeMatches ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                log(`   - Overall result: ${overallSuccess ? '‚úÖ SUCCESS' : '‚ùå FAILED'}`, overallSuccess ? 'success' : 'error');
                
            } catch (error) {
                log(`‚ùå Test failed: ${error.message}`, 'error');
            } finally {
                setButtonsEnabled(true);
            }
        }


        
        // Run all tests
        async function runRealApiTests() {
            setButtonsEnabled(false);
            
            log('üöÄ Starting Real API Tests with Multi-language Motor Commands\n');
            log('=' * 60);
            
            let currentPwm = 100;
            let messageHistory = [];
            let testResults = [];
            
            log(`üìä Initial state: PWM = ${currentPwm}, Message history = ${messageHistory.length} items\n`);
            
            for (let i = 0; i < testCases.length; i++) {
                const testCase = testCases[i];
                
                log(`\n${'='.repeat(50)}`);
                log(`üß™ TEST ${i + 1}: ${testCase.language} Command`);
                log(`${'='.repeat(50)}`);
                log(`Command: "${testCase.command}"`);
                log(`Expected: ${testCase.expectedPwmChange} motor power`);
                log(`Audio samples: ${testCase.audioData.length}`);
                log(`Duration: ${(testCase.audioData.length / 16000).toFixed(2)}s`);
                
                try {
                    const result = await callRealApi(
                        testCase.audioData,
                        currentPwm,
                        messageHistory,
                        testCase.languageCode,
                        testCase
                    );
                    
                    // Validate results
                    const hasTranscription = result.transcription && result.transcription.length > 0;
                    const hasResponse = result.response && result.response.length > 0;
                    const pwmIncreased = result.newPwmValue > result.previousPwm;
                    const intentMatches = result.intentDetected === testCase.expectedIntent;
                    const pwmChangeMatches = (testCase.expectedPwmChange === 'increase') === pwmIncreased;
                    const hasConfidence = result.confidence !== undefined && result.confidence > 0;
                    const overallSuccess = result.success && hasTranscription && intentMatches && pwmChangeMatches;
                    
                    log(`\nüìã Validation Results:`);
                    log(`   - API success: ${result.success ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                    log(`   - Has transcription: ${hasTranscription ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                    log(`   - Has response: ${hasResponse ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                    log(`   - Has confidence: ${hasConfidence ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                    log(`   - Intent detection: ${intentMatches ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                    log(`   - PWM change direction: ${pwmChangeMatches ? '‚úÖ PASS' : '‚ùå FAIL'}`);
                    log(`   - Overall result: ${overallSuccess ? '‚úÖ SUCCESS' : '‚ùå FAILED'}`, overallSuccess ? 'success' : 'error');
                    
                    // Update state for next test
                    currentPwm = result.newPwmValue || currentPwm;
                    messageHistory = result.msgHis || messageHistory;
                    
                    testResults.push({
                        testCase: testCase,
                        result: result,
                        validation: {
                            hasTranscription,
                            hasResponse,
                            intentMatches,
                            pwmChangeMatches,
                            hasConfidence,
                            overall: overallSuccess
                        }
                    });
                    
                } catch (error) {
                    log(`‚ùå Test ${i + 1} failed with error: ${error.message}`, 'error');
                    testResults.push({
                        testCase: testCase,
                        error: error.message,
                        validation: { overall: false }
                    });
                }
                
                // Add delay between tests
                await new Promise(resolve => setTimeout(resolve, 1000));
            }
            
            // Final summary
            log(`\n${'='.repeat(60)}`);
            log(`üìä FINAL REAL API TEST SUMMARY`);
            log(`${'='.repeat(60)}`);
            
            const passedTests = testResults.filter(r => r.validation && r.validation.overall).length;
            const totalTests = testResults.length;
            
            log(`Tests passed: ${passedTests}/${totalTests}`, passedTests === totalTests ? 'success' : 'warning');
            log(`Success rate: ${((passedTests / totalTests) * 100).toFixed(1)}%`);
            log(`Final PWM value: ${currentPwm}`);
            log(`Message history length: ${messageHistory.length}`);
            
            testResults.forEach((result, index) => {
                const status = result.validation && result.validation.overall ? '‚úÖ' : '‚ùå';
                const type = result.validation && result.validation.overall ? 'success' : 'error';
                log(`${status} Test ${index + 1} (${result.testCase.language}): ${result.testCase.command}`, type);
            });
            
            log(`\nüîß Real API Pipeline Verification:`);
            log(`   ‚úÖ Audio data generation: Working`);
            log(`   ‚úÖ Int16Array transmission: Working`);
            log(`   ${passedTests > 0 ? '‚úÖ' : '‚ùå'} Real Google Speech-to-Text API: ${passedTests > 0 ? 'Working' : 'Check API'}`);
            log(`   ${passedTests > 0 ? '‚úÖ' : '‚ùå'} Real Google Gemini LLM API: ${passedTests > 0 ? 'Working' : 'Check API'}`);
            log(`   ‚úÖ PWM control logic: Working`);
            log(`   ${passedTests === totalTests ? '‚úÖ' : '‚ö†Ô∏è'} Multi-language support: ${passedTests === totalTests ? 'Working' : 'Partial'}`);
            
            log(`\nüèÅ Real API test completed!`, 'success');
            log(`üí° ${passedTests === totalTests ? 'All systems operational!' : 'Some issues detected - check logs above.'}`, passedTests === totalTests ? 'success' : 'warning');
            
            // Show stats
            showTestStats(testResults, passedTests, totalTests, currentPwm, messageHistory.length);
            
            setButtonsEnabled(true);
        }
        
        function showTestStats(results, passed, total, finalPwm, historyLength) {
            const statsDiv = document.getElementById('test-stats');
            const statsContent = document.getElementById('stats-content');
            
            statsContent.innerHTML = `
                <div>‚úÖ Tests Passed: ${passed}/${total}</div>
                <div>üìà Success Rate: ${((passed / total) * 100).toFixed(1)}%</div>
                <div>‚ö° Final PWM: ${finalPwm}</div>
                <div>üí¨ Message History: ${historyLength} items</div>
                <div>üåç Languages Tested: English, Spanish, Chinese</div>
                <div>üéØ Real APIs: Google Speech-to-Text + Gemini LLM</div>
                <div>üîó Endpoint: directaudiotopwm-qveg3gkwxa-ew.a.run.app</div>
            `;
            
            statsDiv.style.display = 'block';
        }
        
        // Make functions globally accessible
        window.startOptimizedVoiceControl = startOptimizedVoiceControl;
        window.stopOptimizedVoiceControl = stopOptimizedVoiceControl;
        window.testApiConnectivity = testApiConnectivity;
        window.testLLMOnly = testLLMOnly;
        window.testSingleLanguage = testSingleLanguage;
        window.runRealApiTests = runRealApiTests;
        window.clearOutput = clearOutput;
        
        // Initialize
        log('üß™ Real API Test Runner Initialized', 'success');
        log('Ready to test with direct audio processing via Gemini 2.0!');
        log('‚ö†Ô∏è  Note: This will make real API calls and may incur costs.');
    </script>
</body>
</html>