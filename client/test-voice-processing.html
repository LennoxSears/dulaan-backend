<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Voice Processing Flow</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .status { padding: 10px; margin: 10px 0; border-radius: 5px; }
        .success { background-color: #d4edda; color: #155724; }
        .error { background-color: #f8d7da; color: #721c24; }
        .info { background-color: #d1ecf1; color: #0c5460; }
        .log { background-color: #f8f9fa; padding: 10px; margin: 10px 0; border-left: 4px solid #007bff; font-family: monospace; white-space: pre-wrap; max-height: 300px; overflow-y: auto; }
    </style>
</head>
<body>
    <h1>Voice Processing Flow Test</h1>
    
    <div id="status" class="status info">Loading...</div>
    
    <h3>Voice Processing Logic Test</h3>
    <button onclick="testSilenceDetection()">Test Silence Detection</button>
    <button onclick="testSpeechPackaging()">Test Speech Packaging</button>
    <button onclick="testEventDrivenFlow()">Test Event-Driven Flow</button>
    
    <div id="log" class="log"></div>
    
    <script src="dulaan-browser-bundled.js"></script>
    <script>
        let logDiv = document.getElementById('log');
        let statusDiv = document.getElementById('status');
        
        function log(message) {
            console.log(message);
            logDiv.textContent += new Date().toLocaleTimeString() + ': ' + message + '\n';
            logDiv.scrollTop = logDiv.scrollHeight;
        }
        
        function setStatus(message, type = 'info') {
            statusDiv.textContent = message;
            statusDiv.className = 'status ' + type;
        }
        
        document.addEventListener('DOMContentLoaded', function() {
            try {
                if (typeof window.dulaan !== 'undefined' && window.DULAAN_COMPONENTS) {
                    setStatus('‚úÖ Bundle loaded successfully!', 'success');
                    log('Dulaan SDK loaded with components: ' + Object.keys(window.DULAAN_COMPONENTS).join(', '));
                } else {
                    setStatus('‚ùå Bundle failed to load', 'error');
                }
            } catch (error) {
                setStatus('‚ùå Error: ' + error.message, 'error');
                log('Bundle test error: ' + error.message);
            }
        });
        
        function testSilenceDetection() {
            log('\n=== Testing Silence Detection ===');
            
            try {
                const audioProcessor = window.dulaan.audio;
                
                // Test with silent audio (all zeros)
                const silentData = new Float32Array(1600).fill(0);
                const silentBase64 = btoa(String.fromCharCode.apply(null, new Uint8Array(silentData.buffer)));
                
                log('Testing silent audio chunk...');
                const silentResult = audioProcessor.processAudioChunk(silentBase64);
                log('Silent result: ' + JSON.stringify(silentResult, null, 2));
                
                // Test with speech-like audio (random noise)
                const speechData = new Float32Array(1600);
                for (let i = 0; i < speechData.length; i++) {
                    speechData[i] = (Math.random() - 0.5) * 0.2; // Moderate energy
                }
                const speechBase64 = btoa(String.fromCharCode.apply(null, new Uint8Array(speechData.buffer)));
                
                log('Testing speech-like audio chunk...');
                const speechResult = audioProcessor.processAudioChunk(speechBase64);
                log('Speech result: ' + JSON.stringify(speechResult, null, 2));
                
                log('‚úÖ Silence detection test completed');
                
            } catch (error) {
                log('‚ùå Silence detection test failed: ' + error.message);
            }
        }
        
        function testSpeechPackaging() {
            log('\n=== Testing Speech Packaging ===');
            
            try {
                const audioProcessor = window.dulaan.audio;
                
                // Add some test audio data to the buffer
                const testData = new Float32Array(1600);
                for (let i = 0; i < testData.length; i++) {
                    testData[i] = Math.sin(i * 0.1) * 0.1; // Sine wave
                }
                const testBase64 = btoa(String.fromCharCode.apply(null, new Uint8Array(testData.buffer)));
                
                log('Adding test audio to buffer...');
                audioProcessor.processAudioChunk(testBase64);
                
                log('Testing speech packaging...');
                const packagedSpeech = audioProcessor.packageSpeechSegmentSync();
                
                if (packagedSpeech) {
                    log('‚úÖ Speech packaged successfully, length: ' + packagedSpeech.length);
                } else {
                    log('‚ö†Ô∏è No speech data to package');
                }
                
            } catch (error) {
                log('‚ùå Speech packaging test failed: ' + error.message);
            }
        }
        
        function testEventDrivenFlow() {
            log('\n=== Testing Event-Driven Flow ===');
            
            try {
                const audioProcessor = window.dulaan.audio;
                
                // Set up callback to capture speech segments
                let speechSegmentReceived = false;
                audioProcessor.setSpeechSegmentCallback((speechData) => {
                    log('üéØ Speech segment callback triggered! Data length: ' + speechData.length);
                    speechSegmentReceived = true;
                });
                
                log('Simulating speech detection followed by silence...');
                
                // Simulate speech chunks
                for (let i = 0; i < 10; i++) {
                    const speechData = new Float32Array(1600);
                    for (let j = 0; j < speechData.length; j++) {
                        speechData[j] = (Math.random() - 0.5) * 0.3; // Speech-like energy
                    }
                    const speechBase64 = btoa(String.fromCharCode.apply(null, new Uint8Array(speechData.buffer)));
                    audioProcessor.processAudioChunk(speechBase64);
                }
                
                log('Added 10 speech chunks, now adding silence to trigger packaging...');
                
                // Simulate silence chunks to trigger packaging
                for (let i = 0; i < 30; i++) { // More than SILENCE_TIMEOUT (25)
                    const silentData = new Float32Array(1600).fill(0);
                    const silentBase64 = btoa(String.fromCharCode.apply(null, new Uint8Array(silentData.buffer)));
                    audioProcessor.processAudioChunk(silentBase64);
                }
                
                setTimeout(() => {
                    if (speechSegmentReceived) {
                        log('‚úÖ Event-driven flow test passed - callback was triggered!');
                    } else {
                        log('‚ùå Event-driven flow test failed - callback was not triggered');
                    }
                    
                    // Clean up
                    audioProcessor.removeSpeechSegmentCallback();
                }, 100);
                
            } catch (error) {
                log('‚ùå Event-driven flow test failed: ' + error.message);
            }
        }
    </script>
</body>
</html>